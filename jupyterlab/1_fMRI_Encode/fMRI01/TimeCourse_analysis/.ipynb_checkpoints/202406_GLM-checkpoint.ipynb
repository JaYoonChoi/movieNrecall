{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d97ef2-13ab-49d8-a005-f006162f89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load required modules\n",
    "import warnings, sys, os ## system\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\") # ignore warnings\n",
    "\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime    \n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product, combinations\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "from bids import BIDSLayout, BIDSValidator\n",
    "\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn import plotting, image\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix, FirstLevelModel\n",
    "from nilearn.image import concat_imgs, mean_img\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0620bef4-c4e8-4e47-98a0-058cb398a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files \n",
    "story_dir = '/mnt/c/Users/since/Dropbox/Lab/Projects/CJY/_DATA'\n",
    "May_dir = '/mnt/c/Users/since/Desktop/KdramaMay/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bd6e3c0-bd79-445a-b97b-f683d8696893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 27\n",
      " 28 29 30 31 32 33]\n"
     ]
    }
   ],
   "source": [
    "#Subject check \n",
    "sub_sm = np.arange(1,34)\n",
    "sub_sm_exclude = [0, 8, 25] #exclude 9 & 26\n",
    "subjects = np.delete(sub_sm, sub_sm_exclude)\n",
    "#print(subject)\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c17d341-2926-4340-97b2-b68d90f0e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load story sequence \n",
    "import scipy.io as sio\n",
    "\n",
    "all_story = {}\n",
    "# Load May Data\n",
    "for sub in subjects:\n",
    "    #print(sub)\n",
    "    mat = sio.loadmat(glob.glob(os.path.join(story_dir, 'fMRItdsgn', 'fMRI_May', f'sub-{sub}_*.mat'))[0])\n",
    "    story = []\n",
    "    for i in np.arange(0,4):\n",
    "        temp = mat['subj'][0][0][7][0][i][0]\n",
    "        if temp == 'Blind Date':\n",
    "            temp = 'BlindDate'\n",
    "        elif temp == 'Runningman':\n",
    "            temp = 'RunningMan'\n",
    "        elif temp == 'neighbors':\n",
    "            temp = 'Neighbors'\n",
    "        story = np.append(story, temp)\n",
    "    #all_story[str(int(sub)+8)] = story\n",
    "    all_story[sub] = story\n",
    "#Fix story sequence\n",
    "#story_sequece = all_story[]\n",
    "#story_sequece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a9b2e-cf12-42d2-bef0-66960f7e8099",
   "metadata": {},
   "source": [
    "# Building Design Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1190447-fd14-42b6-81dd-8186113d2cdc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Just for Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcdf3c3f-5b52-436b-bf97-81cb1791b8f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    onset  duration  trial_type\n",
      "0      23       4.5    nei0post\n",
      "1     102       4.5    nei1post\n",
      "2     131       4.5    nei2post\n",
      "3     171       4.5    nei3post\n",
      "4      55       4.5    nei0post\n",
      "5      84       4.5    nei1post\n",
      "6      98       4.5    nei2post\n",
      "7     131       4.5    nei3post\n",
      "8     171       4.5    nei4post\n",
      "9     213       4.5    run0post\n",
      "10    236       4.5    run1post\n",
      "11    256       4.5    run2post\n",
      "12    318       4.5    run3post\n",
      "13    351       4.5    run4post\n",
      "14    210       4.5    run0post\n",
      "15    244       4.5    run1post\n",
      "16    256       4.5    run2post\n",
      "17    318       4.5    run3post\n",
      "18    351       4.5    run4post\n",
      "19    355       4.5  blind0post\n",
      "20    408       4.5  blind1post\n",
      "21    426       4.5  blind2post\n",
      "22    492       4.5  blind3post\n",
      "23    516       4.5  blind4post\n",
      "24    390       4.5  blind0post\n",
      "25    467       4.5  blind1post\n",
      "26    491       4.5  blind2post\n",
      "27    516       4.5  blind3post\n",
      "28    572       4.5  dream0post\n",
      "29    629       4.5  dream1post\n",
      "30    663       4.5  dream2post\n",
      "31    696       4.5  dream3post\n",
      "32    556       4.5  dream0post\n",
      "33    571       4.5  dream1post\n",
      "34    629       4.5  dream2post\n",
      "35    664       4.5  dream3post\n",
      "36    689       4.5  dream4post\n",
      "37    711       4.5  dream5post\n"
     ]
    }
   ],
   "source": [
    "# EB condition \n",
    "\n",
    "vis_eb =  {'run' : [15,42,65,85,147,180], 'nei': [15,32,111,140,180], 'dream': [15,41,98,132,165], 'blind': [15,19,72,90,156,180]}\n",
    "aud_eb = {'run' : [15,39,73,85,147,180], 'nei': [15,64,93,107,140,180], 'dream': [15,25,40,98,133,158,180], 'blind': [15,54,131,155,180]}\n",
    "event_boundary = {'vis': vis_eb, 'aud':aud_eb}\n",
    "eb_events_list = []\n",
    "for story in np.arange(0,4):    \n",
    "    \n",
    "    thisStory = storyName[all_story[sub][story]] \n",
    "    \n",
    "    for eb in ['vis','aud']:\n",
    "        boundary = event_boundary[eb]\n",
    "        duration = np.full(len(boundary[thisStory]), 1.5)\n",
    "        \n",
    "        for event in range(len(boundary[thisStory])):\n",
    "                        \n",
    "            eb_events_list.append({\n",
    "                'onset': onset[cond][story] + boundary[thisStory][event],\n",
    "                'duration':duration[event],\n",
    "                'trial_type': f'{thisStory}{event}boundary'\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "eb_events = pd.DataFrame(eb_events_list)\n",
    "\n",
    "# print(events)\n",
    "# preEvent condition \n",
    "vis_onset = {'run' : [15,42,65,85,147], 'nei': [15,32,111,140], 'dream': [15,41,98,132], 'blind': [15,19,72,90,156]}\n",
    "aud_onset = {'run' : [15,39,73,85,147], 'nei': [15,64,93,107,140], 'dream': [15,25,40,98,133,158], 'blind': [15,54,131,155]}\n",
    "event_onset = {'vis': vis_onset, 'aud':aud_onset}\n",
    "onset_events_list = []\n",
    "\n",
    "for story in np.arange(0,4):    \n",
    "    \n",
    "    thisStory = storyName[all_story[sub][story]] \n",
    "    \n",
    "    for eb in ['vis','aud']:\n",
    "        start = event_onset[eb]\n",
    "        duration = np.full(len(start[thisStory]), 6)\n",
    "        \n",
    "        for event in range(len(start[thisStory])):\n",
    "                        \n",
    "            onset_events_list.append({\n",
    "                'onset': onset[cond][story] + 3 + start[thisStory][event],\n",
    "                'duration':duration[event],\n",
    "                'trial_type': f'{thisStory}{event}pre'\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "onset_events = pd.DataFrame(onset_events_list)\n",
    "#print(onset_events)\n",
    "\n",
    "#postEvent condition \n",
    "vis_offset = {'run' : [42,65,85,147,180], 'nei': [32,111,140,180], 'dream': [41,98,132,165], 'blind': [19,72,90,156,180]}\n",
    "aud_offset = {'run' : [39,73,85,147,180], 'nei': [64,93,107,140,180], 'dream': [25,40,98,133,158,180], 'blind': [54,131,155,180]}\n",
    "\n",
    "event_offset = {'vis': vis_offset, 'aud':aud_offset}\n",
    "offset_events_list = []\n",
    "\n",
    "for story in np.arange(0,4):    \n",
    "    \n",
    "    thisStory = storyName[all_story[sub][story]] \n",
    "    \n",
    "    for eb in ['vis','aud']:\n",
    "        end = event_offset[eb]\n",
    "        duration = np.full(len(end[thisStory]), 4.5)\n",
    "        \n",
    "        for event in range(len(end[thisStory])):\n",
    "                        \n",
    "            offset_events_list.append({\n",
    "                'onset': onset[cond][story] + end[thisStory][event] - 9,\n",
    "                'duration':duration[event],\n",
    "                'trial_type': f'{thisStory}{event}post'\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "offset_events = pd.DataFrame(offset_events_list)\n",
    "print(offset_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6d18829-e26b-4f34-bc07-1221c3208c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.concat([eb_events, onset_events, offset_events])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5b9ba9-2525-44e3-8b22-01bad1e0c317",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Concat runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d7297-4200-4f9e-8f88-a3dce424f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "for sub in subjects: \n",
    "    print(sub)\n",
    "\n",
    "    encoding_files = glob.glob(os.path.join(May_dir,'denoised', 'denoised_2024', f'sub-*{sub}_task-encoding_run-*_4scNsm.nii.gz'))\n",
    "\n",
    "    # Load the NIfTI files\n",
    "    nii1 = nib.load(encoding_files[0])\n",
    "    nii2 = nib.load(encoding_files[0])\n",
    "\n",
    "    # Get the data arrays from the NIfTI files\n",
    "    data1 = nii1.get_fdata()\n",
    "    data2 = nii2.get_fdata()\n",
    "\n",
    "    # Concatenate the data along the desired axis\n",
    "    # Adjust axis as needed (0, 1, 2 for x, y, z; 3 for time/4D)\n",
    "    concatenated_data = np.concatenate((data1, data2), axis=3)  # Example concatenation along the 4th dimension\n",
    "\n",
    "    # Create a new NIfTI image from the concatenated data\n",
    "    concatenated_nii = nib.Nifti1Image(concatenated_data, nii1.affine)\n",
    "\n",
    "    # Save the new NIfTI image to a file\n",
    "    concat_img_path = os.path.join(May_dir,'denoised', 'denoised_2024', f\"sub-{sub}_task-encoding_concatenated.nii.gz\")\n",
    "    nib.save(concatenated_nii, concat_img_path)\n",
    "\n",
    "print('Concatenation complete. File saved as concatenated_file.nii.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a60157-1d88-4163-9db9-bd4222e974d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building Desing Matrix & Fitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7ce17-e0f4-4be5-b7af-764b9302230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sequence = np.where(all_story[sub]=='Dream')[0][0]\n",
    "# cond = 'Dream'+str(int(sequence)+1)\n",
    "\n",
    "isi = 15  # Inter-stimulus interval between events in seconds\n",
    "tr = 1.5  # Repetition time in seconds\n",
    "dummy = 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1deee6-4d40-4934-a3c9-06bebafcdaac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_dm = {} \n",
    "for sub in subjects:\n",
    "    print(sub)\n",
    "    \n",
    "    # Generate the events data frame\n",
    "    sequence = np.where(all_story[sub]=='Dream')[0][0]\n",
    "    cond = 'Dream'+str(int(sequence)+1)\n",
    "    \n",
    "    \n",
    "    # EB condition \n",
    "    vis_eb =  {'run' : [15,42,65,85,147,180], 'nei': [15,32,111,140,180], 'dream': [15,41,98,132,165], 'blind': [15,19,72,90,156,180]}\n",
    "    aud_eb = {'run' : [15,39,73,85,147,180], 'nei': [15,64,93,107,140,180], 'dream': [15,25,40,98,133,158,180], 'blind': [15,54,131,155,180]}\n",
    "    event_boundary = {'vis': vis_eb, 'aud':aud_eb}\n",
    "    eb_events_list = []\n",
    "    for story in np.arange(0,4):    \n",
    "\n",
    "        thisStory = storyName[all_story[sub][story]] \n",
    "\n",
    "        for eb in ['vis','aud']:\n",
    "            boundary = event_boundary[eb]\n",
    "            duration = np.full(len(boundary[thisStory]), 1.5)\n",
    "\n",
    "            for event in range(len(boundary[thisStory])):\n",
    "\n",
    "                eb_events_list.append({\n",
    "                    'onset': onset[cond][story] + boundary[thisStory][event],\n",
    "                    'duration':duration[event],\n",
    "                    'trial_type': f'{thisStory}{event}boundary'\n",
    "                })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    eb_events = pd.DataFrame(eb_events_list)\n",
    "\n",
    "    # print(events)\n",
    "    # preEvent condition \n",
    "    vis_onset = {'run' : [15,42,65,85,147], 'nei': [15,32,111,140], 'dream': [15,41,98,132], 'blind': [15,19,72,90,156]}\n",
    "    aud_onset = {'run' : [15,39,73,85,147], 'nei': [15,64,93,107,140], 'dream': [15,25,40,98,133,158], 'blind': [15,54,131,155]}\n",
    "    event_onset = {'vis': vis_onset, 'aud':aud_onset}\n",
    "    onset_events_list = []\n",
    "\n",
    "    for story in np.arange(0,4):    \n",
    "\n",
    "        thisStory = storyName[all_story[sub][story]] \n",
    "\n",
    "        for eb in ['vis','aud']:\n",
    "            start = event_onset[eb]\n",
    "            duration = np.full(len(start[thisStory]), 6)\n",
    "\n",
    "            for event in range(len(start[thisStory])):\n",
    "\n",
    "                onset_events_list.append({\n",
    "                    'onset': onset[cond][story] + 3 + start[thisStory][event],\n",
    "                    'duration':duration[event],\n",
    "                    'trial_type': f'{thisStory}{event}pre'\n",
    "                })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    onset_events = pd.DataFrame(onset_events_list)\n",
    "    #print(onset_events)\n",
    "\n",
    "    #postEvent condition \n",
    "    vis_offset = {'run' : [42,65,85,147,180], 'nei': [32,111,140,180], 'dream': [41,98,132,165], 'blind': [19,72,90,156,180]}\n",
    "    aud_offset = {'run' : [39,73,85,147,180], 'nei': [64,93,107,140,180], 'dream': [25,40,98,133,158,180], 'blind': [54,131,155,180]}\n",
    "\n",
    "    event_offset = {'vis': vis_offset, 'aud':aud_offset}\n",
    "    offset_events_list = []\n",
    "\n",
    "    for story in np.arange(0,4):    \n",
    "\n",
    "        thisStory = storyName[all_story[sub][story]] \n",
    "\n",
    "        for eb in ['vis','aud']:\n",
    "            end = event_offset[eb]\n",
    "            duration = np.full(len(end[thisStory]), 4.5)\n",
    "\n",
    "            for event in range(len(end[thisStory])):\n",
    "\n",
    "                offset_events_list.append({\n",
    "                    'onset': onset[cond][story] + end[thisStory][event] - 9,\n",
    "                    'duration':duration[event],\n",
    "                    'trial_type': f'{thisStory}{event}post'\n",
    "                })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    offset_events = pd.DataFrame(offset_events_list)\n",
    "\n",
    "    events = pd.concat([eb_events, onset_events, offset_events])\n",
    "    sub_dm[sub] = events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd86dbc-58b1-48cc-9934-4a17ac75486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_onset = {'run':[15,40,68,85,147], 'dream':[15,40,77,132], 'nei':[15,33,65, 81, 107, 140], 'blind':[15, 55, 90, 131, 157]}\n",
    "eb_offset = {'run':[40,68,85,147, 180], 'dream':[40,77,132,165], 'nei':[33,65, 81, 107, 140, 180], 'blind':[55, 90, 131, 157, 180]}\n",
    "\n",
    "# Data Load & Trimming \n",
    "onset = {'Dream1': [0, 165, 345, 525], 'Dream2': [0, 180, 345, 525], 'Dream3': [0, 180, 360, 525], 'Dream4': [0, 180, 345, 540]}\n",
    "storyName = {'RunningMan': 'run', 'BlindDate': 'blind', 'Dream':'dream', 'Neighbors':'nei'}\n",
    "\n",
    "# sequence = np.where(all_story[sub]=='Dream')[0][0]\n",
    "# cond = 'Dream'+str(int(sequence)+1)\n",
    "\n",
    "isi = 15  # Inter-stimulus interval between events in seconds\n",
    "tr = 1.5  # Repetition time in seconds\n",
    "dummy = 9 \n",
    "\n",
    "#load BOLD Volume\n",
    "for sub in subjects: \n",
    "    print(sub)\n",
    "    \n",
    "#     # Generate the events data frame\n",
    "#     sequence = np.where(all_story[sub]=='Dream')[0][0]\n",
    "#     cond = 'Dream'+str(int(sequence)+1)\n",
    "    \n",
    "#     events_list = []\n",
    "#     for story in np.arange(0,4):    \n",
    "#         thisStory = storyName[all_story[sub][story]] \n",
    "#         duration = [ai - bi for ai, bi in zip(eb_offset[thisStory], eb_onset[thisStory])]\n",
    "\n",
    "#         for event in range(len(eb_onset[thisStory])):\n",
    "#             events_list.append({\n",
    "#                 'onset': onset[cond][story] + eb_onset[thisStory][event],\n",
    "#                 'duration': duration[event],\n",
    "#                 'trial_type': f'{thisStory}{event}'\n",
    "#             })\n",
    "    events = pd.DataFrame(sub_dm[sub])\n",
    "    \n",
    "    # Calculate the total number of scans\n",
    "    total_time = events['onset'].iloc[-1] +  events['duration'].iloc[-1] + dummy  # Time after last event ends\n",
    "    n_scans = int(total_time / tr)+1\n",
    "    frame_times = np.arange(0, n_scans * tr, tr) # Frame times: time for each scan\n",
    "    \n",
    "    # Build a design matrix \n",
    "    design_matrix = make_first_level_design_matrix(frame_times,events,drift_model='cosine')\n",
    "    print('event_size' , events.shape)\n",
    "    print('desingMatrix_size', design_matrix.shape)\n",
    "\n",
    "    # Plot the design matrix\n",
    "    plot_design_matrix(design_matrix)\n",
    "    plot_path = os.path.join(May_dir, 'analysis', 'designMatirx', f\"sub-{sub}_task-encoding_designMatrix.png\")\n",
    "    plt.savefig(plot_path)\n",
    "\n",
    "    #========================================================================================================\n",
    "    encoding_files = glob.glob(os.path.join(May_dir,'denoised', 'denoised_2024', f\"sub-{sub}_task-encoding_run-0{i+1}_concatenated.nii.gz\"))\n",
    "    \n",
    "    # Load fmri imgs for Fitting     \n",
    "    func_imgs = {}\n",
    "    for run in np.arange(0,2):\n",
    "        print(f'Load func_img files: {encoding_files[run]}')\n",
    "        func_imgs[run] = image.load_img(encoding_files[run]) \n",
    "        print('Image shape:', func_imgs[run].shape)\n",
    "\n",
    "    output_dir = os.path.join(May_dir,'analysis', 'betas') \n",
    "    for i in range(0,2):\n",
    "        glm = FirstLevelModel(t_r=1.5, hrf_model='glover', drift_model='cosine')\n",
    "        glm = glm.fit(func_imgs[i], design_matrices=design_matrix)\n",
    "        \n",
    "        beta_map = [glm.compute_contrast(event) for event in events_type]\n",
    "\n",
    "        # Compute and visualize beta maps\n",
    "        #for j, label in enumerate(np.unique(events['trial_type'])):\n",
    "            # Assuming `betas` is a list of 4D beta maps, one for each event\n",
    "            #beta_map = glm.compute_contrast(label)\n",
    "            #all_beta_imgs.append(beta_map)\n",
    "            \n",
    "            #plotting.plot_stat_map(beta_map, title=label, display_mode='z', threshold=2.3, cut_coords=5)\n",
    "        combined_4d_beta_img = nib.concat_images(beta_map)\n",
    "        beta_img_path = os.path.join(output_dir, f\"sub-{sub}_task-encoding_run-0{i+1}_betas_image.nii.gz\")\n",
    "        nib.save(combined_4d_beta_img, beta_img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeaa825-91d5-41df-9bae-092c57d69f44",
   "metadata": {},
   "source": [
    "# 2nd Lv GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69d9510d-3ebd-467f-a23c-34e31988558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_604/4099686182.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0msmall_update_events\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbig_update_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmall_update\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0msmall_update_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbig_update\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mbig_update_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# 2nd-lv GLM:Compare correlations between smallupdate and bigupdate \n",
    "\n",
    "stories = ['RunningMan', 'Dream', 'Blind','Neighbors'] \n",
    "events = ['blind0', 'blind1', 'blind2', 'blind3', 'blind4', 'dream0','dream1', 'dream2', 'dream3', 'nei0', 'nei1', 'nei2', 'nei3','nei4', 'nei5', 'run0', 'run1', 'run2', 'run3', 'run4'],\n",
    "\n",
    "small_update = {'RunningMan': [15,16,17,18,19], 'Dream' : [5,8], 'Blind' : [3,4], 'Neighbors' : [13,14]}\n",
    "bid_update = {'Dream' : [6,7], 'Blind' : [0,1,2], 'Neighbors' : [9,10,11,12]}\n",
    "#story_names = {'RunningMan' : 'run', 'Dream': 'dream', 'Blind' : 'blind', 'Neighbors': 'nei'} \n",
    "\n",
    "# Compare betas between Conditions \n",
    "sub_beta_imgs, sub_correlation= {}, {}  \n",
    "sub_update = {} \n",
    "for sub in subjects: \n",
    "    print(sub) \n",
    "    beta_files = glob.glob(os.path.join(May_dir,'analysis', 'betas', f\"sub-{sub}_task-encoding_run-*_betas_image.nii.gz\"))  \n",
    "    story_update = {}\n",
    "    for run in np.arange(0,2):\n",
    "        beta_img = image.load_img(beta_files[run]) \n",
    "        for story in stories:\n",
    "            small_update_events,big_update_events = [],[]\n",
    "            for sp in small_update[story]:\n",
    "                small_update_events.append(beta_img.get_fdata()[:,:,:,events[0][sp]])\n",
    "            for bp in big_update[story]:\n",
    "                big_update_events.append(beta_img.get_fdata()[:,:,:,events[0][bp]])\n",
    "            story_update[f'small_{story}_{run}'] = image.mean_img(small_update_event)\n",
    "            story_update[f'big_{story}_{run}'] = image.mean_img(big_update_events)\n",
    "    sub_update['sub']= story_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2943476f-66db-445e-aef6-e7e32000cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare small/big mean img \n",
    "story_small_update1 = story_update[['small_RunnignMan_0','small_Dream_0','small_Blind_0','small_Neighbors_0']].mean(axis = 1)\n",
    "story_small_update2 = story_update[['small_RunnignMan_1','small_Dream_1','small_Blind_1','small_Neighbors_1']].mean(axis = 1)\n",
    "story_big_update1 = story_update[['big_RunnignMan_0','big_Dream_0','big_Blind_0','big_Neighbors_0']].mean(axis = 1)\n",
    "story_big_update2 = story_update[['big_RunnignMan_1','big_Dream_1','big_Blind_1','big_Neighbors_1']].mean(axis = 1)\n",
    "small_update_contrast = story_small_update2 - story_small_update1\n",
    "big_update_contrast = story_big_update2 - story_big_update1\n",
    "update_contrast = big_update_contrast - small_update_contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e5f59c-3d94-4695-a9c6-3af23eca4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "from nilearn import plotting\n",
    "\n",
    "# 평균 베타 이미지 플롯\n",
    "display = plotting.plot_stat_map(\n",
    "    mean_beta_img,                     # 평균 베타 이미지\n",
    "    title='Average Beta Image',        # 차트 제목\n",
    "    display_mode='ortho',              # 표시 모드: 'ortho'는 삼면도(X, Y, Z)를 표시합니다.\n",
    "    cut_coords=(0, 0, 0),              # 중심 좌표: 변경하여 다른 뇌 부분을 중심으로 표시할 수 있습니다.\n",
    "    cmap='viridis'                     # 컬러맵: 시각적으로 구분하기 쉽게 컬러맵을 설정할 수 있습니다.\n",
    ")\n",
    "\n",
    "# 플롯 화면에 표시\n",
    "plotting.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri01",
   "language": "python",
   "name": "fmri01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
